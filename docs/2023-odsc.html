<!doctype html>
<html>

<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=10.0, user-scalable=yes">

	<title>MLOps: Monitoring and Managing Drift</title>

	<link rel="stylesheet" href="revealjs/reveal.js/dist/reset.css" />
    <link rel="stylesheet" href="revealjs/reveal.js/dist/reveal.css" />
    <link rel="stylesheet" href="revealjs/reveal.js/dist/theme/white.css" />

    <!-- Theme used for syntax highlighted code -->
	<!-- <link rel="stylesheet" href="revealjs/reveal.js/plugin/highlight/monokai.css"> -->
	<!-- <link rel="stylesheet" href="revealjs/reveal.js/plugin/highlight/zenburn.css"> -->
    <link rel="stylesheet" href="revealjs/highlight-js-github-theme.css" />
    <link rel="stylesheet" href="revealjs/styles.css" />

</head>

<body style="background-color: whitesmoke;">
	<div class="reveal">
		<div class="slides">
<!-- 

https://odsc.com/california/speakers/

I'm excited to confirm your proposal “MLOps: Monitoring and Managing Drift” has been accepted for ODSC West 2023 as an
in-person Half-Day Training.

Half day workshop, could be 75 minutes, then only part I


MLOps: Monitoring and Managing Drift

As soon as your machine learning model goes into production everything changes. 
You now will need to constantly monitor the performance of your model, evaluate whether it is still sufficient and react accordingly.
This, however, can be a challenge when you have no reliable ground truth to recalibrate its performance. 
Typically, you will need to fall back to a surrogate metric that you can measure and that is correlated with the performance of your model.
What those metrics can be and how you track and monitor them is the topic of this workshop.

This workshop consists of two parts:
- Part I: Simulate production on an existing machine learning model and detecting drift
  - an OpenAPI machine learning service will be provided
  - we will use Evidently, Prometheus and Grafana to monitor and detect the drift
- Part II: Interpreting and Analyzing Drift and what to do about it
  - when you have detected drift, you will need to interpret what happened and decide what to do about it
  - among the steps you can take is to retrain your model with new data
  - we might also have to consider to rethink the model architecture or the data we are using

Our objective is to ensure that you are equipped with the essential knowledge and practical tools to proficiently manage
your machine learning models in a real-world production environment.

All services will be provided as Docker images and can be run locally on your machine. 
To have the full experience, you should have Docker and Docker Compose installed. 
Notebooks will additionally be provided as a Colab service so you can also run them without a local installation as a fallback. 


Language: Python
DS Tools: TensorFlow, Evidently, OpenAPI, Docker
Attendees should know how to work with Docker Compose 
All Levels: Drift is a broad topic that can be addressed on many levels
MLOps and Data Engineering


-->


		<section data-markdown class="todo">
			<textarea data-template>
### Aufbau				

Evidently und Drift Detection als Hauptteil inkl. Übung				

Teil 1: so wie OOP, Fallbeispiel etc. Man hat Drift festgestellt
Teil 2: Interpretation, Analyse, Abhilfe

</textarea>
		</section>
		<section data-markdown class="todo">
			<textarea data-template>
## Drift Repo
### Part I:        
- Docker compose für alles bauen
- Drift Repo bauen Docker files Top Level bereithalten

### Part II:        
- analytics notebook hierher bringen
- Schritte fürs Neutrainieren       


</textarea>
		</section>


		    <section data-markdown class="todo">
      <textarea data-template>
### ODSC, nach OOP Talk

- Nach dem Talk mit Generischen Namen ausprobieren
- oder vorher auf dem Gaming Laptop: 
- Liegt es am Webhook in Gitea, Antwort von Tobi:
Der commit trigger ist so implementiert, dass er auf commits in den main branch auf dem gitea repository reagiert.
Wenn du sagst anderes setup, achte auch drauf, dass in Gitea dann der Webhook sauber angelegt worden ist im Gitea
Repository. (Das kann man mit dem Admin User in den Settings des repos nachschauen)

Ansonsten mal im Tekton Dashboard prüfen ob die resourcen alle auch tatsächlich angelegt worden sind.(commit-trigger
usw)

Drift-Repo: 
- docker compose
- Hier gibt es schon ein Docker Compose, vielleicht kann ich mich da bedienen oder zumindest inspirieren lassen
  - https://www.evidentlyai.com/blog/batch-ml-monitoring-architecture
  - https://github.com/evidentlyai/evidently/tree/main/examples/integrations/postgres_grafana_batch_monitoring
  - https://github.com/evidentlyai/evidently/tree/main/examples/integrations/grafana_monitoring_service
  - https://github.com/evidentlyai/evidently/tree/main/examples/integrations/fastapi_monitoring
- Mit Installationsanweisung und Check, ob es geht.  
- Nur Linux, Mac, oder Windows WSL2
- Falls Problem, Issue anlegen

      </textarea>
    </section>
      
	<section data-markdown class="todo">
		<textarea data-template>
### Google Rubic Score			
		</textarea>
    </section>

	<section data-markdown class="todo">
		<textarea data-template>
### Stack ist riesig und erfordert viele Entscheidungen

Lieber gemanagtes Environment nutzen
  
	https://aws.amazon.com/de/sagemaker/clarify/
</textarea>
</section>

<section data-markdown class="todo">
	<textarea data-template>
### Darbietung / Story

- Stringenz in der Story / therefor and but, not and then: https://www.instagram.com/reel/CtxLMBDA35H/?igshid=MTc4MmM1YmI2Ng%3D%3D
- Für die Zusammenfassung B drücken und mich nach vorn stellen

</textarea>
</section>







<section data-markdown class="preparation" style="font-size: large;">
	<textarea data-template>
  
## Mitnehmen
* 30 Spicker ausdrucken
  
  ## 
## Vorbereitung
* Allen Docker Kram einmal wegschmeißen und neu bauen wie in Readme
* gucken, dass alles läuft
* Notebook aufmachen: https://colab.research.google.com/github/djcordhose/mlops/blob/main/insurance-prediction/notebooks/train.ipynb
    
	</textarea>
  </section>
  

<section data-markdown>
    <textarea data-template>
# MLOps: Monitoring and Managing Drift

ODSC West 2023, https://odsc.com/california/speakers/xxx

Oliver Zeigermann

<img src="img/bit.ly_odsc-west-mlops.png" style="height: 200px;">

Slides: https://bit.ly/odsc-west-mlops

<!-- https://djcordhose.github.io/mlops-drift/2023-odsc.html -->
</textarea>
</section>

<section data-markdown>
	<textarea data-template>
### Challenges in Machine Learning Projects

<img src="img/biggest_challenges_ML_MLCon_2023.jpg" style="height: 530px;" class="fragment">

<small>Survey MLConf Berlin 2023</small>
	</textarea>
</section>


<section data-markdown class="fragments">
### MLOps

* MLOps ist abgeleitet von DevOps
* Durch MLOps kommt ML in Produktion und wird in Betrieb gehalten
* Dazu kommen eine Reihe von Werkzeugen und Praktiken zum Einsatz
* Überschneidung aus
  * Softwareentwicklung
  * Operations
  * Data Science
</section>

<section data-markdown>
	<textarea data-template>
  ### Machine Learning Projecs can be thought as running in phases
  
  <img src='img/phases.jpg' style="height: 100%;">
  
  </textarea>
</section>

<section data-markdown>
### MLOps 1.0 vs MLOps 2.0

- MLOps 1.0 - research / experiment centric
- MLOps 2.0 - production first
</section>

<section data-markdown>
### MLOps 1.0 - research / experiment centric
  - Managing experiments  and Version control
    - Model Architecture
    - Training Code
    - Data
    - Artefacts
      - Trained Model 
      - Plots (learning curve, confusion matrix)
  - Tools
    - Mlflow
    - Speadsheets
    - Weights & Biases
    - Comet
</section>

<section data-markdown>
### MLOps 2.0 - production first

  - productionize, deploy, maintain
  - Deployment Pipeline
     - Model Repo
       - Rather Image, as Model does not stand for itself most of the time, rather is a system
       - Data Source and Preproc same code dev and prod (if possible)
  - Real world environment
  - Monitoring
    - Gap between training and prod data?
</section>

<section data-markdown>
	<textarea data-template>
### Fun for the first five minutes
## Create your own MLOps Zine

<div class="container">
  <div class="col">
  <img src="img/zine/teaser.jpg" style="height: 100%;">
  <em>Fold</em>
  </div>
  <div class="col">
  <img src="img/zine/fold.jpg" style="height: 100%;">
  <em>Topology change</em>
  
  </div>
</div>
<br>  
<br>  

<small>We are not aiming for highest production quality, but make something physical that you can take home</small>
</textarea>
</section>

<section data-markdown>
### Phase 0: Enable Organization

_Make sure people on all levels and all roles understand the specific needs and specialties of a machine learning project_

* prepare for 80% garbage factor
* clash of roles
* largest part of job begins *after* production
* this might be the hardest and least part of the overall job

Links
* https://fearlesschangepatterns.com/
* https://www.rejectiontherapy.com/
</section>



<!-- <section data-markdown>
	<textarea data-template>
### MLOps - komplettes Zine

<img src="img/zine/mlops.png" style="height: 530px;" class="fragment">

<small>Bildunterschrit</small>
	</textarea>
</section>
 -->

 <section data-markdown>
	<textarea data-template>
### Use Case: Predict Risk 

<img src="img/zine/use-case.png" style="height: 530px;" class="fragment">

<small>Objective: Risk of potential customer as LOW, MEDIUM, HIGH</small>
	</textarea>
</section>

<section data-markdown>
	<textarea data-template>
### Die Qualität von ML Systemen nimmt meist mit der Zeit ab

<img src="img/zine/degrade.png" style="height: 530px;" class="fragment">

<small>Das gilt nicht nur für ML Anwendungen, aber bei diesen ist es offensichtlicher</small>
	</textarea>
</section>

<section data-markdown>
	<textarea data-template>
### Aktualisierte Modelle sind immer wieder notwendig

<img src="img/zine/intervention.png" style="height: 530px;" class="fragment">

<small>Machine Learning Anwendungen brauchen Wartung</small>
	</textarea>
</section>

<section data-markdown>
	<textarea data-template>
  ### Ohne Ground Truth braucht man eine Ersatzmetrik
  
  <img src="img/zine/drift.png" style="height: 450px;" class="fragment">
  
  
  *Wenn sich die Verteilung der Daten der Anfragen oder Vorhersagen deutlich von denen des Trainings unterscheiden* 
  </textarea>
  </section>
  

		</div>
	</div>
	<script src="revealjs/reveal.js/dist/reveal.js"></script>
	<script src="revealjs/reveal.js/plugin/notes/notes.js"></script>
	<script src="revealjs/reveal.js/plugin/markdown/markdown.js"></script>
	<script src="revealjs/reveal.js/plugin/highlight/highlight.js"></script>
	<script src="revealjs/config.js"></script>

</body>

</html>
