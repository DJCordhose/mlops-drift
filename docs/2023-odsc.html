<!doctype html>
<html lang="en">

<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=10.0, user-scalable=yes">

	<title>MLOps: Monitoring and Managing Drift</title>

	<link rel="stylesheet" href="revealjs/reveal.js/dist/reset.css" />
    <link rel="stylesheet" href="revealjs/reveal.js/dist/reveal.css" />
    <link rel="stylesheet" href="revealjs/reveal.js/dist/theme/white.css" />

    <!-- Theme used for syntax highlighted code -->
	<!-- <link rel="stylesheet" href="revealjs/reveal.js/plugin/highlight/monokai.css"> -->
	<!-- <link rel="stylesheet" href="revealjs/reveal.js/plugin/highlight/zenburn.css"> -->
    <link rel="stylesheet" href="revealjs/highlight-js-github-theme.css" />
    <link rel="stylesheet" href="revealjs/styles.css" />

</head>

<body style="background-color: whitesmoke;">
	<div class="reveal">
		<div class="slides">
<!-- 

https://odsc.com/california/speakers/

MLOps: Monitoring and Managing Drift

As soon as your machine learning model goes into production everything changes.
You now will need to constantly monitor the performance of your model, evaluate whether it is still sufficient and react accordingly.
This, however, can be a challenge when you have no reliable ground truth to recalibrate its performance.
Typically, you will need to fall back to a surrogate metric that you can measure and that is correlated with the performance of your model.
What those metrics can be and how you track and monitor them is the topic of this workshop.

This workshop consists of two parts:
- Part I: Simulate production on an existing machine learning model and detecting drift
  - an OpenAPI machine learning service will be provided
  - we will use Evidently, Prometheus and Grafana to monitor and detect the drift
- Part II: Interpreting and Analyzing Drift and what to do about it
  - when you have detected drift, you will need to interpret what happened and decide what to do about it
  - among the steps you can take is to retrain your model with new data
  - we might also have to consider to rethink the model architecture or the data we are using

Our objective is to ensure that you are equipped with the essential knowledge and practical tools to proficiently manage
your machine learning models in a real-world production environment.

All services will be provided as Docker images and can be run locally on your machine or in a cloud environment using Gitpod.

-->


		<!-- <section data-markdown class="todo">
			<textarea data-template>
### Aufbau				

Evidently und Drift Detection als Hauptteil inkl. Übung				

Teil 1: so wie OOP, Fallbeispiel etc. Man hat Drift festgestellt
Teil 2: Interpretation, Analyse, Abhilfe

</textarea>
		</section>
		<section data-markdown class="todo">
			<textarea data-template>
## Drift Repo
### Part I:        
- Docker compose für alles bauen
- Drift Repo bauen Docker files Top Level bereithalten

### Part II:        
- analytics notebook hierher bringen
- Schritte fürs Neutrainieren       


</textarea>
		</section>


		    <section data-markdown class="todo">
      <textarea data-template>
### ODSC, nach OOP Talk

- Nach dem Talk mit Generischen Namen ausprobieren
- oder vorher auf dem Gaming Laptop: 
- Liegt es am Webhook in Gitea, Antwort von Tobi:
Der commit trigger ist so implementiert, dass er auf commits in den main branch auf dem gitea repository reagiert.
Wenn du sagst anderes setup, achte auch drauf, dass in Gitea dann der Webhook sauber angelegt worden ist im Gitea
Repository. (Das kann man mit dem Admin User in den Settings des repos nachschauen)

Ansonsten mal im Tekton Dashboard prüfen ob die resourcen alle auch tatsächlich angelegt worden sind.(commit-trigger
usw)

Drift-Repo: 
- docker compose
- Hier gibt es schon ein Docker Compose, vielleicht kann ich mich da bedienen oder zumindest inspirieren lassen
  - https://www.evidentlyai.com/blog/batch-ml-monitoring-architecture
  - https://github.com/evidentlyai/evidently/tree/main/examples/integrations/postgres_grafana_batch_monitoring
  - https://github.com/evidentlyai/evidently/tree/main/examples/integrations/grafana_monitoring_service
  - https://github.com/evidentlyai/evidently/tree/main/examples/integrations/fastapi_monitoring
- Mit Installationsanweisung und Check, ob es geht.  
- Nur Linux, Mac, oder Windows WSL2
- Falls Problem, Issue anlegen

      </textarea>
    </section>

    <section data-markdown class="todo">
		<textarea data-template>
### Architecture

<img src="img/monitoring-stack.jpg" style="height: 530px;" class="fragment">
		</textarea>
    </section>


	<section data-markdown class="todo">
		<textarea data-template>
### Für den Analyse Teil

Interested in how a feature influences machine learning model predictions on average?

https://www.linkedin.com/posts/christoph-molnar_interested-in-how-a-feature-influences-machine-activity-7098247765155004416-nONi
		</textarea>
    </section>


	<section data-markdown class="todo">
		<textarea data-template>
### Stack ist riesig und erfordert viele Entscheidungen

Lieber gemanagtes Environment nutzen
  
	https://aws.amazon.com/de/sagemaker/clarify/
</textarea>
</section>

<section data-markdown class="todo">
	<textarea data-template>
### Darbietung / Story

- Stringenz in der Story / therefor and but, not and then: https://www.instagram.com/reel/CtxLMBDA35H/?igshid=MTc4MmM1YmI2Ng%3D%3D
- Für die Zusammenfassung B drücken und mich nach vorn stellen

</textarea>
</section> -->




<section data-markdown>
    <textarea data-template>
# MLOps: Monitoring and Managing Drift
<h2 style="color: red;">Work in Progress</h2>

ODSC West 2023, https://odsc.com/speakers/mlops-monitoring-and-managing-drift/
Monday, 30th October, 10:00 AM - 1:15 PM

Oliver Zeigermann


<img src="img/bit.ly_odsc-west-mlops.png" style="height: 150px;"><br>
Slides: https://bit.ly/odsc-west-mlops

<!-- https://djcordhose.github.io/mlops-drift/2023-odsc.html -->
</textarea>
</section>

<section data-markdown class="fragments">
## What is Monitoring and Managing Drift all about?

1. _MonitoringDrift_: You want to know that there might be a problem with the quality of your model _before_ 
   1. your (internal or external) partners notice
   1. your users notice
   1. you lose trust
   1. your business is impacted
   1. you are in the news

2. _Managing Drift_: Once noticed, you want to be able to react quickly and effectively
   1. analyze if there is a problem in the first place
   1. if so, what to do about it
</section>
  
<section data-markdown>
## How to prepare

* install the project as described in the readme: https://github.com/DJCordhose/mlops-drift/blob/main/README.md#installation

* do not stress yourself, if you can not get this up and running
  * there will be time for this in the workshop (even though not a lot)
  * you can also just watch and learn,  you will get a lot of benefit even without running the code
  * the second part should work entirely without a local installation
  * when forming teams, it is sufficient to have one person with a working installation
</section>


<section data-markdown>
    <textarea data-template>
## Who is Olli

<div style="display: flex;">
<div style="flex: 50%;">
<a href='https://oreilly.de/produkt/machine-learning-kurz-gut-2/'>
<img src='img/ml-buch-v2.jpg' height="400">
</a>
</div>
<div style="flex: 50%; font-size: x-large;">
<img src='img/olli-opa.jpeg'>
</div>
</div>
<p>
<a target="_blank" href="mailto:oliver@zeigermann.de">Oliver Zeigermann</a>:
Machine Learning Engineer/Architect from Hamburg, Germany
</p>    
</textarea>
</section>


<section data-markdown>
	<textarea data-template>
## Wait, are these all the slides?

* the story for this workshop is here: https://github.com/DJCordhose/mlops-drift/blob/main/docs/story.md
* some texts/images/sources/links are still be in German, but this will be fixed before the workshop
* the slides following are just a support for the story

	</textarea>
</section>

<section data-markdown>
	<textarea data-template>
## Material referenced from the story

https://github.com/DJCordhose/mlops-drift/blob/main/docs/story.md

	</textarea>
</section>

<section data-markdown id="use-case">
	<textarea data-template>
### Use Case: Predict Risk 

<img src="img/zine/use-case.png" style="height: 530px;" class="fragment">

<small>Objective: Risk of potential customer as LOW, MEDIUM, HIGH</small>
	</textarea>
</section>

<section data-markdown class="fragments" id="demo-request">
  <textarea data-template>
<img src="img/mlops/swagger-sample-request.jpg" style="height: 40vh;">

*Result of example*
```
{
  "prediction": "LOW",
  "probabilities": {
    "HIGH": 0.0003246392006985843,
    "MEDIUM": 0.022435296326875687,
    "LOW": 0.9772400259971619
  },
  "predictor_type": "MODEL"
}
```
</textarea>
</section>

<section data-markdown class="fragments" id="all-notebooks">
  <textarea data-template>

1. Simulation of use case, generates all the data (not used in this workshop): https://colab.research.google.com/github/djcordhose/mlops-drift/blob/main/datasets/generate-causal.ipynb?hl=en
1. Training and retraining: https://colab.research.google.com/github/djcordhose/mlops-drift/blob/main/notebooks/train.ipynb?hl=en
1. Drift monitoring and calculation: https://colab.research.google.com/github/djcordhose/mlops-drift/blob/main/notebooks/drift.ipynb?hl=en
1. Analysis of drift cause: https://colab.research.google.com/github/djcordhose/mlops-drift/blob/main/notebooks/analysis.ipynb?hl=en
  * Example from Evidently (https://www.evidentlyai.com/blog/mlops-monitoring): https://colab.research.google.com/github/djcordhose/mlops-drift/blob/main/notebooks/Evidently_Sandbox.ipynb?hl=en
</textarea>
</section>

<!-- <section data-markdown style="font-size: xx-large;" id="starting-point" lang="de">
  <textarea data-template>
## Unser Ausgangspunkt

Notebooks sind das klassische Werkzeug der ML Entwicklung: 
https://colab.research.google.com/github/djcordhose/mlops-drift/blob/main/notebooks/train.ipynb

* Neuronales Netzwerk mit TensorFlow
* 3 Hidden Layers, 100 Neuronen pro Layer
* 1500 Datensätze insgesamt
  * Training auf 1200 Datensätzen
  * Test/Validation auf 300 Datensätzen
* Accuracy Training/Test > 85%

</textarea>
</section>   -->

<section data-markdown style="font-size: xx-large;" id="starting-point" lang="en">
  <textarea data-template>
## Our starting point

Notebooks are the classic tool for ML development:
https://colab.research.google.com/github/djcordhose/mlops-drift/blob/main/notebooks/train.ipynb?hl=en

* Neural network with TensorFlow
* 3 hidden layers, 100 neurons per layer
* 1500 data sets in total
  * Training on 1200 data sets
  * Test/validation on 300 data sets
* Accuracy training/test > 85%
  </textarea>
</section>


<section data-markdown id="model-degrade">
	<textarea data-template>
### The quality of ML systems usually deteriorates over time

<img src="img/zine/degrade.png" style="height: 530px;" class="fragment">

<small>This is not only true for ML applications, but it is more obvious with them</small>
</textarea>
</section>


<section data-markdown id="model-intervention">
	<textarea data-template>
### Updated models are necessary frequently

<img src="img/zine/intervention.png" style="height: 530px;" class="fragment">

<small>Machine Learning applications need maintenance</small>
	</textarea>
</section>

<section data-markdown id="model-drift">
	<textarea data-template>
### Without Ground Truth you need a surrogate metric
  
  <img src="img/zine/drift.png" style="height: 450px;" class="fragment">
  
  
*Distribution of data of requests or predictions differs significantly from that of training* 
  </textarea>
  </section>
  

  <section data-markdown class="fragments" id="age-distribution">
    <textarea data-template>
  ### Distribution of Ages at the time of training
  
  <img src="img/causal-insurance/age-reference.png">
  
  </textarea>
  </section>
  
  <section data-markdown class="fragments" id="age-drift-1">
    <textarea data-template>
    ### does this drift? 
    
    <img src="img/causal-insurance/age_no_drift_p75_no_clue.png">
    
    </textarea>
    </section>
    
    <section data-markdown class="fragments" id="age-drift-2">
    <textarea data-template>
    ### and this? 
    
    <img src="img/causal-insurance/age_drift_p0_no_clue.png">
    
    </textarea>
    </section>

<section data-markdown id="monitoring-stack">
	<textarea data-template>
### Monitoring with Evidently, Prometheus und Grafana

<img src="img/mlops/evidently_grafana_service.png">

<small>https://evidentlyai.com/blog/evidently-and-grafana-ml-monitoring-live-dashboards
<br>
https://docs.evidentlyai.com/integrations/evidently-and-grafana
</small>

</textarea>
</section>

<section data-markdown lang="de" id="types-drift">
	<textarea data-template>
### Zusammenfassung: Arten von Drift

* _Covariate / Input / Data drift_: Verteilung der Eingabe hat sich geändert
* _Prior / Label / Prediction drift_: Verteilung der Vorhersage hat sich geändert
* _Concept / Model drift_: Zusammenhang zwischen Eingabe und Vorhersage hat sich geändert

<img src="https://docs.seldon.io/projects/alibi-detect/en/stable/_images/bg_2d_drift.png" style="height: 100%;">

<small>https://docs.seldon.io/projects/alibi-detect/en/stable/cd/background.html#what-is-drift
</small>
</textarea>
</section>

<section data-markdown style="font-size: x-large;" lang="de" id="drift-interpretation">
	<textarea data-template>
## Drift erfordert Interpretation

Wenn die Welt sich ändert, ist Drift zu erwarten und damit ok

|   | Positive Interpretation, keine Maßnahme erforderlich  | Negative Interpretation, Maßnahme erforderlich  |
|---|---|---|
| *Data und Prediction Drift*  | wichtige Features haben sich geändert, Modell kommt klar und extrapoliert gut, z.B.: Höheres Alter, mehr Risiko  |  wichtige Features haben sich geändert, Modell extrapoliert nicht sinnvoll |
| *Data aber kein Prediction Drift*  | keine wichtigen Features geändert, das Modell ist robust genug für den Drift  | wichtige Features geändert, Modell extrapoliert nicht sinnvoll |
| *Prediction aber kein Data Drift*  | ???  | wahrscheinlich Concept Drift, neue Analyse der Situation notwendig |
|   |   |   |

</textarea>
</section>

<section data-markdown lang="de" id="stats-test">
	<textarea data-template>
## Welcher Statistischer Test / welche Metrik?

es gibt leider nicht den einen passenden Test

* manche passen nur gut für kleine (< 1000) Datenmengen
  * unsere Datenmengen sind größer als 1000
* manche können nicht nur auf numerischen sondern kategorischen Daten arbeiten
  * wir brauchen beides
* manche sind zwischen 0 und 1 normiert
  * das ist uns eher egal
* unsere Metriken
  * Wasserstein Metrik für numerische Daten
  * Jensen-Shannon Distanz für kategorische Daten  

https://evidentlyai.com/blog/data-drift-detection-large-datasets
</textarea>
</section>

<section data-markdown lang="de" id="Wasserstein">
	<textarea data-template>
### Die Wasserstein-Metrik

_Wenn jede Verteilung als ein Haufen von „Erde“ angehäuft auf dem metrischen Raum betrachtet wird, dann beschreibt diese
Metrik die minimalen „Kosten“ der Umwandlung eines Haufens in den anderen._

* nicht zu sensitiv, zeigt nur größere Veränderungen an
* normiert in Veränderungen in Standardabweichungen
* kann (offensichtlich) über 1 gehen
* ab 0.1 gehen wir von einem Drift aus
* funktioniert nur für numerische Daten

https://en.wikipedia.org/wiki/Wasserstein_metric
</textarea>
</section>

<section data-markdown lang="de" id="Jensen-Shannon">
	<textarea data-template>
### Jensen-Shannon Divergenz

* Jensen-Shannon Distanz ist wie Wurzel aus der Divergenz, das ist unsere Metrik
* zwischen 0 und 1
* ab 0.1 gehen wir von einem Drift aus
* funktioniert auch für kategorische Daten
* basiert auf Kullback–Leibler Divergenz, relative Entropie
* Histogramme werden verglichen, Größe des Samples daher egal
* Binning für kategorische Daten offensichtlich
* Intuition: wie viel Information/Entropie/Überraschung steckt im Unterschied der beiden Verteilungen?


https://en.wikipedia.org/wiki/Jensen%E2%80%93Shannon_divergence
https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence
</textarea>
</section>

<section data-markdown id="ml-system">
	<textarea data-template>
### A ML model does not go into production all by itself

<img src="img/ml-system-postits.jpg" style="height: 550px;">

</textarea>
</section>


<section data-markdown id="what-else">
### What else / more material
</section>

<section data-markdown class="fragments" lang="de">
## Was kann man sonst noch monitoren?
  
* Qualität der Daten
  * wie verändern sich fehlende oder falsche Felder
  * Plausibilität
* Daten Drift
  * Verteilung der Eingabedaten
* Prediction Drift   
  * Was gibt das Modell aus?
* Whenn man Ground Truth hat
  * Metrik für die Qualität der Vorhersage wie beim Training verwendet
  * Unterschiedliche typische Qualitäts-Metriken
  * Vorsicht: jede noch so gute Metrik ist wieder nur ein Surrogat für die Qualität der Vorhersage 
* Requests pro Minute/Stunde/Tag
* User Feedback
* Lastly, there is the business or product KPI: https://www.evidentlyai.com/blog/ml-monitoring-metrics#4-business-metrics-and-kpi

  </section>
  
  <section data-markdown lang="de">
  ## Datenqualität
  
  * Felder
    * fehlen
    * ungültig
    * falsch / unplausibel / Wertebereich verlassen
  * Features 
    * konstante (die (meisten) Eingaben haben (fast) denselben Wert)
    * leere
    * fast leer
    * Korrelationen zwischen Features
  </section>
    
  
  <section data-markdown class="fragments"  lang="de">
    <textarea data-template>
  ### Was kann man sonst noch machen
  
  * Outlier-Detection
    * Unser Modell wird nicht extrapolieren können
    * Werte außerhalb des Trainings-Bereichs werden wahrscheinlich unrealistisch sicher vorhergesagt
    * Ausreißer müssen ohne Ground Truth entdeckt werden 
  * Adversarial Detection
    * Bestimmte Eingaben können absichtlich eine grob falsche Vorhersage herbei führen 
    * Solche Eingaben können erkannt und korrigiert werden
    * Dazu kann z.B. ein Autoencoder benutzt werden, der die Eingabe korrigiert
  
  
  <small>https://docs.seldon.io/projects/alibi-detect/en/stable/od/methods.html
  <br>
  https://docs.seldon.io/projects/alibi-detect/en/stable/ad/methods.html
  </small>
  </textarea>
  </section>
  
  <section data-markdown class="fragments" lang="de">
    <textarea data-template>
  ### Drift Detection für Bilder
  
  _Bild auf typische aggregierte Eigenschaften reduzieren_  
  * Input Drift mit Histogrammen von Low-Level-Features (HSV): https://towardsdatascience.com/detecting-semantic-drift-within-image-data-6a59a0e768c6
  * Input Drift mit Dimensions-Reduktion: https://docs.seldon.io/projects/alibi-detect/en/stable/examples/cd_ks_cifar10.html 
  * Model Drift durch Vergleich mit destilliertem Modell: https://docs.seldon.io/projects/alibi-detect/en/stable/examples/cd_distillation_cifar10.html 
  * Ein komplettes Beispiel mit Alibi-Detect: https://docs.seldon.io/projects/alibi-detect/en/stable/examples/alibi_detect_deploy.html#4.-Drift-detection-with-Kolmogorov-Smirnov
  * Anomalien in Bildern: https://29a.ch/photo-forensics
  </textarea>
  </section>

  <section data-markdown>
  <textarea data-template>
### Drift Detection for Text

* https://docs.seldon.io/projects/alibi-detect/en/stable/examples/cd_text_imdb.html
* https://www.evidentlyai.com/blog/embedding-drift-detection
</textarea>
</section>

  <section data-markdown class="fragments" lang="de">
    <textarea data-template>
  ### Wann liegt Ground Truth vor?
  
  *Menschliche Experten können die Ground Truth*
  * *bestimmen* 
    * sobald ein Mensch die Entscheidungen nachprüft / revidiert
    * bei einem Proposal-System kann das sehr schnell sein
    * bei Dunkelverarbeitung sollte dies in regelmäßigen Abständen passieren
  * *nicht bestimmen*
    * wir müssen Realitäten abwarten
    * bei Zeitreihen wird auf die nahe Zukunft vorhergesagt, sobald diese Eintritt kann überprüft werden
    * oft sind solche Realitäten erst nach einiger Zeit wahrnehmbar und unterliegen statistischen Schwankungen (wie bei uns)
  </textarea>
  </section>
  
  <section data-markdown class="fragments" lang="de">
    <textarea data-template>
  ### Unsere Vorhersage selbst erzeugt Drift
  
  * Ein Deployment ändert das unsere Rolle von Beobachter zu Akteur
  * Wir versichern nur Leute mit einer guten Risiko Prognose
    * Wenn nicht, warum sollten wir dann eine überhaupt eine Prognose machen?
  * Unsere GT wird mehr und mehr gute Fahrer haben
    * Zumindest ist das unsere Hoffnung (sonst hätte die Prognose nicht geklappt)
  * Falls nicht (False Negative, Type II Fehler)
    * haben Menschen gelernt, unser System auszutricksen?
    * "Dann versichert eben meine Tochter den Wagen"
  * Haben wir gute Fahrer aus verstehen nicht versichert (False Positive, Type I Fehler)
    * Möglichkeit: *epsilon-greedy* meistens der Vorhersage glauben, aber manchmal (epsilon) auch einen Fahrer mit schlechter Prognose versichern 
    * Vorhersage mit allen Wahrscheinlichkeiten geht in unsere Datenbank ein
  
  https://twitter.com/ChristophMolnar/status/1569644089724764160
  </textarea>
  </section>

  <section data-markdown>
    <textarea data-template>
### Google Rubric Score
* https://developers.google.com/machine-learning/guides/rules-of-ml
* https://research.google/pubs/pub46555/
* https://research.google/pubs/pub45742/
* https://laszlo.substack.com/p/article-review-the-ml-test-score
    </textarea>
    </section>

<section data-markdown>
	<textarea data-template>
### Challenges in Machine Learning Projects

<img src="img/biggest_challenges_ML_MLCon_2023.jpg" style="height: 530px;" class="fragment">

<small>Survey MLConf Berlin 2023</small>
	</textarea>
</section>


<section data-markdown>
	<textarea data-template>
  ### Machine Learning Projecs can be thought as running in phases
  
  <img src='img/ml-phases-small-en.jpg' style="height: 100%;">
  
  </textarea>
</section>
    
<!--

<section data-markdown class="preparation">
	<textarea data-template>
1. 30 Zines vorbereiten und mitbrigen
1. Gitpod starten
   1. im Workspace auch die lokale installation machen
1. Lokale installation starten
   * ich hab eine lokale Installation auf meinem Rechner, falls irgendwas nicht geht
	</textarea>
</section>

<section data-markdown>
	<textarea data-template>
## Why this workshop?    

_I have rarely been this excited about a workshop like this one_
We have all skills coming together for this kind of work:
1. DS, mostly second part
1. Dev
1. Ops    
	</textarea>
</section>



<section data-markdown class="fragments">
  ### MLOps
  
  * MLOps is derived from DevOps
  * MLOps brings ML into production and keeps it in operation
  * A number of tools and practices are used for this
  * Overlap from
    * Software development
    * Operations
    * Data Science
  </section>
  
  
<section data-markdown>
### MLOps 1.0 vs MLOps 2.0

- MLOps 1.0 - research / experiment centric
- MLOps 2.0 - production first
</section>

<section data-markdown>
### MLOps 1.0 - research / experiment centric

  - Managing experiments  and Version control
    - Model Architecture
    - Training Code
    - Data
    - Artefacts
      - Trained Model 
      - Plots (learning curve, confusion matrix)
  - Tools
    - Mlflow
    - Speadsheets
    - Weights & Biases
    - Comet
</section>

<section data-markdown>
### MLOps 2.0 - production first

  - productionize, deploy, maintain
  - Deployment Pipeline
     - Model Repo
       - Rather Image, as Model does not stand for itself most of the time, rather is a system
       - Data Source and Preproc same code dev and prod (if possible)
  - Real world environment
  - Monitoring
    - Gap between training and prod data?
</section>

<section data-markdown>
	<textarea data-template>
### Fun for the first five minutes
## Create your own MLOps Zine

<div class="container">
  <div class="col">
  <img src="img/zine/teaser.jpg" style="height: 100%;">
  <em>Fold</em>
  </div>
  <div class="col">
  <img src="img/zine/fold.jpg" style="height: 100%;">
  <em>Topology change</em>
  
  </div>
</div>
<br>  
<br>  

<small>We are not aiming for highest production quality, but make something physical that you can take home</small>
</textarea>
</section> -->

<!-- <section data-markdown>
	<textarea data-template>
### MLOps - komplettes Zine

<img src="img/zine/mlops.png" style="height: 530px;" class="fragment">

<small>Bildunterschrit</small>
	</textarea>
</section>
 -->

 <!-- 

  <section data-markdown>
    <textarea data-template>
    ### Machine Learning Projecs can be thought as running in phases
    
    <img src='img/ml-phases-en.jpg' style="height: 100%;">
    
    </textarea>
  </section>
  
  
  <section data-markdown>
  ### Phase 0: Enable Organization
  
  _Make sure people on all levels and all roles understand the specific needs and specialties of a machine learning project_
  
  * prepare for 80% garbage factor
  * clash of roles
  * largest part of job begins *after* production
  * this might be the hardest and least part of the overall job
  
  Links
  * https://fearlesschangepatterns.com/
  * https://www.rejectiontherapy.com/
  </section>
  
  <section data-markdown>
    <textarea data-template>
  ### Phase 1: Data Engineering
    
    _Make sure you have a reliable, reproducible and scalable data pipeline_
    
    * data versioning
    * data validation
    * data reproducibility
    * data scalability
    
    Links
    * https://www.kdnuggets.com/2021/03/data-version-control-what-why-how.html
    *
  </textarea>
  </section>
  
     -->

		</div>
	</div>
	<script src="revealjs/reveal.js/dist/reveal.js"></script>
	<script src="revealjs/reveal.js/plugin/notes/notes.js"></script>
	<script src="revealjs/reveal.js/plugin/markdown/markdown.js"></script>
	<script src="revealjs/reveal.js/plugin/highlight/highlight.js"></script>
	<script src="revealjs/config.js"></script>

</body>

</html>
