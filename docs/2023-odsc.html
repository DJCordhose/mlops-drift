<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=10.0, user-scalable=yes">

  <title>MLOps: Monitoring and Managing Drift</title>

  <link rel="stylesheet" href="revealjs/reveal.js/dist/reset.css" />
  <link rel="stylesheet" href="revealjs/reveal.js/dist/reveal.css" />
  <link rel="stylesheet" href="revealjs/reveal.js/dist/theme/white.css" />

  <!-- Theme used for syntax highlighted code -->
  <!-- <link rel="stylesheet" href="revealjs/reveal.js/plugin/highlight/monokai.css"> -->
  <!-- <link rel="stylesheet" href="revealjs/reveal.js/plugin/highlight/zenburn.css"> -->
  <link rel="stylesheet" href="revealjs/highlight-js-github-theme.css" />
  <link rel="stylesheet" href="revealjs/styles.css" />

</head>

<body style="background-color: whitesmoke;">
  <div class="reveal">
    <div class="slides">
      <!-- 

https://odsc.com/california/speakers/

MLOps: Monitoring and Managing Drift

As soon as your machine learning model goes into production everything changes.
You now will need to constantly monitor the performance of your model, evaluate whether it is still sufficient and react accordingly.
This, however, can be a challenge when you have no reliable ground truth to recalibrate its performance.
Typically, you will need to fall back to a surrogate metric that you can measure and that is correlated with the performance of your model.
What those metrics can be and how you track and monitor them is the topic of this workshop.

This workshop consists of two parts:
- Part I: Simulate production on an existing machine learning model and detecting drift
  - an OpenAPI machine learning service will be provided
  - we will use Evidently, Prometheus and Grafana to monitor and detect the drift
- Part II: Interpreting and Analyzing Drift and what to do about it
  - when you have detected drift, you will need to interpret what happened and decide what to do about it
  - among the steps you can take is to retrain your model with new data
  - we might also have to consider to rethink the model architecture or the data we are using

Our objective is to ensure that you are equipped with the essential knowledge and practical tools to proficiently manage
your machine learning models in a real-world production environment.

All services will be provided as Docker images and can be run locally on your machine or in a cloud environment using Gitpod.

-->


      <!-- <section data-markdown class="todo">
			<textarea data-template>
### Aufbau				

Evidently und Drift Detection als Hauptteil inkl. Übung				

Teil 1: so wie OOP, Fallbeispiel etc. Man hat Drift festgestellt
Teil 2: Interpretation, Analyse, Abhilfe

</textarea>
		</section>
		<section data-markdown class="todo">
			<textarea data-template>
## Drift Repo
### Part I:        
- Docker compose für alles bauen
- Drift Repo bauen Docker files Top Level bereithalten

### Part II:        
- analytics notebook hierher bringen
- Schritte fürs Neutrainieren       


</textarea>
		</section>


		    <section data-markdown class="todo">
      <textarea data-template>
### ODSC, nach OOP Talk

- Nach dem Talk mit Generischen Namen ausprobieren
- oder vorher auf dem Gaming Laptop: 
- Liegt es am Webhook in Gitea, Antwort von Tobi:
Der commit trigger ist so implementiert, dass er auf commits in den main branch auf dem gitea repository reagiert.
Wenn du sagst anderes setup, achte auch drauf, dass in Gitea dann der Webhook sauber angelegt worden ist im Gitea
Repository. (Das kann man mit dem Admin User in den Settings des repos nachschauen)

Ansonsten mal im Tekton Dashboard prüfen ob die resourcen alle auch tatsächlich angelegt worden sind.(commit-trigger
usw)

Drift-Repo: 
- docker compose
- Hier gibt es schon ein Docker Compose, vielleicht kann ich mich da bedienen oder zumindest inspirieren lassen
  - https://www.evidentlyai.com/blog/batch-ml-monitoring-architecture
  - https://github.com/evidentlyai/evidently/tree/main/examples/integrations/postgres_grafana_batch_monitoring
  - https://github.com/evidentlyai/evidently/tree/main/examples/integrations/grafana_monitoring_service
  - https://github.com/evidentlyai/evidently/tree/main/examples/integrations/fastapi_monitoring
- Mit Installationsanweisung und Check, ob es geht.  
- Nur Linux, Mac, oder Windows WSL2
- Falls Problem, Issue anlegen

      </textarea>
    </section>

    <section data-markdown class="todo">
		<textarea data-template>
### Architecture

<img src="img/monitoring-stack.jpg" style="height: 530px;" class="fragment">
		</textarea>
    </section>


	<section data-markdown class="todo">
		<textarea data-template>
### Für den Analyse Teil

Interested in how a feature influences machine learning model predictions on average?

https://www.linkedin.com/posts/christoph-molnar_interested-in-how-a-feature-influences-machine-activity-7098247765155004416-nONi
		</textarea>
    </section>


	<section data-markdown class="todo">
		<textarea data-template>
### Stack ist riesig und erfordert viele Entscheidungen

Lieber gemanagtes Environment nutzen
  
	https://aws.amazon.com/de/sagemaker/clarify/
</textarea>
</section>

<section data-markdown class="todo">
	<textarea data-template>
### Darbietung / Story

- Stringenz in der Story / therefor and but, not and then: https://www.instagram.com/reel/CtxLMBDA35H/?igshid=MTc4MmM1YmI2Ng%3D%3D
- Für die Zusammenfassung B drücken und mich nach vorn stellen

</textarea>
</section> -->

<!-- 
<section data-markdown class="preparation">
# Meine Vorbereitung

* Alle Services lokal laufen haben
  * http://localhost:8080
  * http://localhost:8080/metrics/
  * http://localhost:9090/graph?g0.expr=drift_score_by_columns&g0.tab=1&g0.stacked=0&g0.show_exemplars=0&g0.range_input=1h
  * http://localhost:3000
* Gitpod als Fallback offen haben  
* Localhost braucht Internet, das schon öffnen
* Als roter Faden: https://github.com/DJCordhose/mlops-drift/blob/main/docs/story.md
* Als Überblick die Grafik in Whiteboard öffnen um darauf zeichnen zu können
  * Zeigen wo wir sind und mit Highlighter markieren
* Wie lange dauert das?
  * `./scripts/curl-drift-prediction.sh http://localhost:8080`
  * `./scripts/curl-drift-mock.sh http://localhost:8080`  
</section>
 -->


<!--  
## Preparation
1. make sure you have installed the project as described in https://github.com/DJCordhose/mlops-drift/blob/main/README.md#installation
1. Introduce yourself to your neighbors and build teams of 2-4 people
   * what do you do
   * what do you know already
   * what questions do you wish answered today? what topics addressed?  
   * you can of course participate all by yourself, but it is highly recommended to form a team
1. Start project as described in Readme: 
   1. local: docker compose up
   1. remote: https://gitpod.io/#https://github.com/DJCordhose/mlops-drift


## How you can benefit
There is a lot of material to be covered, so there will be limited time to try things completely one your own.

There are different modes of participation, you will benefit from all of them. 
Choose depending on previous knowledge and your preferences:
1. No installation on your side necessary:
   1. Do this in cinema mode
   1. Ask questions at any time
1. At least some parts should be running
   1. Do what Olli does in sync
   1. Fork at any point and make your own experiments, you are welcome to give a report of what you learned
 -->
 <section data-markdown>
  <textarea data-template>
## MLOps: Monitoring and Managing Drift
# Preparation

1. Wifi is on the back of your badge
1. These slides: https://bit.ly/odsc-west-mlops
1. Start project using Gitpod https://gitpod.io/#https://github.com/DJCordhose/mlops-drift
   1. Login using Github Account when asked to
   1. Choose the large machine when asked to
1. Open the story for you to follow: https://bit.ly/odsc-2023-mlops-story
1. Introduce yourself to your neighbors and build teams of 2-4 people
1. Questions and discussions welcome at any time
</textarea>
</section>

      <section data-markdown>
        <textarea data-template>
# MLOps: Monitoring and Managing Drift

ODSC West 2023, https://odsc.com/speakers/mlops-monitoring-and-managing-drift/
Monday, 30th October, 10:00 AM - 1:15 PM

Oliver Zeigermann


<img src="img/bit.ly_odsc-west-mlops.png" style="height: 150px;"><br>
These Slides: https://bit.ly/odsc-west-mlops

Project: https://github.com/DJCordhose/mlops-drift
<!-- https://djcordhose.github.io/mlops-drift/2023-odsc.html -->
</textarea>
      </section>

      <section data-markdown class="fragments">
## What is Monitoring and Managing Drift all about?

1. _MonitoringDrift_: You want to know that there might be a problem with the quality of your model _before_
    1. your (internal or external) partners notice
    1. your users notice
    1. you lose trust
    1. your business is impacted
    1. you are in the news

2. _Managing Drift_: Once noticed, you want to be able to react quickly and effectively
    1. analyze if there is a problem in the first place
    1. if so, what to do about it
      </section>

      <section data-markdown>
## How to prepare

* install the project as described in the readme:
https://github.com/DJCordhose/mlops-drift/blob/main/README.md#installation

* do not stress yourself, if you can not get this up and running
* there will be time for this in the workshop (even though not a lot)
* you can also just watch and learn, you will get a lot of benefit even without running the code
* the second part should work entirely without a local installation
* when forming teams, it is sufficient to have one person with a working installation
      </section>


      <section data-markdown>
        <textarea data-template>
## Who is Olli

<div style="display: flex;">
<div style="flex: 50%;">
<a href='https://oreilly.de/produkt/machine-learning-kurz-gut-2/'>
<img src='img/ml-buch-v2.jpg' height="400">
</a>
</div>
<div style="flex: 50%; font-size: x-large;">
<img src='img/olli-opa.jpeg'>
</div>
</div>
<p>
<a target="_blank" href="mailto:oliver@zeigermann.de">Oliver Zeigermann</a>:
Machine Learning Engineer/Architect from Hamburg, Germany
</p>    
</textarea>
      </section>


      <section data-markdown>
        <textarea data-template>
## Wait, are these all the slides?

* the story for this workshop is here: https://github.com/DJCordhose/mlops-drift/blob/main/docs/story.md
* the slides following are just a support for the story

	</textarea>
      </section>

      <section data-markdown id="use-case">
        <textarea data-template>
### Use Case: Predict Risk 

<img src="img/zine/use-case.png" style="height: 530px;" class="fragment">

<small>Objective: Risk of potential customer as LOW, MEDIUM, HIGH</small>
	</textarea>
      </section>

      <section data-markdown class="fragments" id="demo-request">
        <textarea data-template>
<img src="img/mlops/swagger-sample-request.jpg" style="height: 40vh;">

*Result of example*
```
{
  "prediction": "LOW",
  "probabilities": {
    "HIGH": 0.0003246392006985843,
    "MEDIUM": 0.022435296326875687,
    "LOW": 0.9772400259971619
  },
  "predictor_type": "MODEL"
}
```
</textarea>
      </section>

      <!-- <section data-markdown style="font-size: xx-large;" id="starting-point" lang="de">
  <textarea data-template>
## Unser Ausgangspunkt

Notebooks sind das klassische Werkzeug der ML Entwicklung: 
https://colab.research.google.com/github/djcordhose/mlops-drift/blob/main/notebooks/train.ipynb

* Neuronales Netzwerk mit TensorFlow
* 3 Hidden Layers, 100 Neuronen pro Layer
* 1500 Datensätze insgesamt
  * Training auf 1200 Datensätzen
  * Test/Validation auf 300 Datensätzen
* Accuracy Training/Test > 85%

</textarea>
</section>   -->

      <section data-markdown style="font-size: xx-large;" id="starting-point" lang="en">
        <textarea data-template>
## Our starting point

Notebooks are the classic tool for ML development:
https://colab.research.google.com/github/djcordhose/mlops-drift/blob/main/notebooks/train.ipynb?hl=en

* Neural network with TensorFlow
* 3 hidden layers, 100 neurons per layer
* 1500 data sets in total
  * Training on 1200 data sets
  * Test/validation on 300 data sets
* Accuracy training/test > 85%
  </textarea>
      </section>


      <section data-markdown id="model-degrade">
        <textarea data-template>
### The quality of ML systems usually deteriorates over time

<img src="img/zine/degrade.png" style="height: 530px;" class="fragment">

<small>This is not only true for ML applications, but it is more obvious with them</small>
</textarea>
      </section>


      <section data-markdown id="model-intervention">
        <textarea data-template>
### Updated models are necessary frequently

<img src="img/zine/intervention.png" style="height: 530px;" class="fragment">

<small>Machine Learning applications need maintenance</small>
	</textarea>
      </section>

      <section data-markdown id="model-drift">
        <textarea data-template>
### Without Ground Truth you need a surrogate metric
  
  <img src="img/zine/drift.png" style="height: 450px;" class="fragment">
  
  
*Distribution of data of requests or predictions differs significantly from that of training* 
  </textarea>
      </section>


      <section data-markdown class="fragments" id="age-distribution">
        <textarea data-template>
  ### Distribution of Ages at the time of training
  
  <img src="img/causal-insurance/age-reference.png">
  
  </textarea>
      </section>

      <section data-markdown class="fragments" id="age-drift-1">
        <textarea data-template>
    ### does this drift? 
    
    <img src="img/causal-insurance/age_no_drift_p75_no_clue.png">
    
    </textarea>
      </section>

      <section data-markdown class="fragments" id="age-drift-2">
        <textarea data-template>
    ### and this? 
    
    <img src="img/causal-insurance/age_drift_p0_no_clue.png">
    
    </textarea>
      </section>

      <section data-markdown id="monitoring-stack">
        <textarea data-template>
### Monitoring with Evidently, Prometheus und Grafana

<img src="img/mlops/evidently_grafana_service.png">

<small>https://evidentlyai.com/blog/evidently-and-grafana-ml-monitoring-live-dashboards
<br>
https://docs.evidentlyai.com/integrations/evidently-and-grafana
</small>

</textarea>
      </section>

      <!-- <section data-markdown lang="de" id="types-drift">
	<textarea data-template>
### Zusammenfassung: Arten von Drift

* _Covariate / Input / Data drift_: Verteilung der Eingabe hat sich geändert
* _Prior / Label / Prediction drift_: Verteilung der Vorhersage hat sich geändert
* _Concept / Model drift_: Zusammenhang zwischen Eingabe und Vorhersage hat sich geändert

<img src="https://docs.seldon.io/projects/alibi-detect/en/stable/_images/bg_2d_drift.png" style="height: 100%;">

<small>https://docs.seldon.io/projects/alibi-detect/en/stable/cd/background.html#what-is-drift
</small>
</textarea>
</section> -->

      <section data-markdown lang="en" id="types-drift">
        <textarea data-template>
### Summary: Types of Drift

_Understanding the difference between data and concept drift is useful when interpreting the changes. However, to
  detect them, we would typically use the same approach._
  
  
* _Covariate / Input / Data drift_: Distribution of the input has changed
* _Prior / Label / Prediction drift_: Distribution of the prediction has changed
* _Concept / Model drift_: Relationship between input and prediction has changed

<img src="https://docs.seldon.io/projects/alibi-detect/en/stable/_images/bg_2d_drift.png" style="height: 100%;">

<small>https://docs.seldon.io/projects/alibi-detect/en/stable/cd/background.html#what-is-drift
</small>
</textarea>
      </section>



      <!-- <section data-markdown class="fragments" lang="de">
## Was kann man sonst noch monitoren?
  
* Qualität der Daten
  * wie verändern sich fehlende oder falsche Felder
  * Plausibilität
* Daten Drift
  * Verteilung der Eingabedaten
* Prediction Drift   
  * Was gibt das Modell aus?
* Whenn man Ground Truth hat
  * Metrik für die Qualität der Vorhersage wie beim Training verwendet
  * Unterschiedliche typische Qualitäts-Metriken
  * Vorsicht: jede noch so gute Metrik ist wieder nur ein Surrogat für die Qualität der Vorhersage 
* Requests pro Minute/Stunde/Tag
* User Feedback
* Lastly, there is the business or product KPI: https://www.evidentlyai.com/blog/ml-monitoring-metrics#4-business-metrics-and-kpi

  </section> -->

      <section data-markdown class="fragments" lang="en" style="font-size: x-large;">
## What else can be monitored?

* Quality of the data
  * how do missing or wrong fields change
  * plausibility
  <!-- * Data Drift
* distribution of the input data -->
  <!-- * Prediction Drift
* What does the model output? -->
* When you have Ground Truth
  * Metric for the quality of the prediction as used in training
  * Different typical quality metrics
  * Caution: no matter how good the metric, it is again only a surrogate for the quality of the prediction
* Which model/fallback was used  
* Requests per minute/hour/day
* Latency
* Error Rate
* User Feedback
* Lastly, there is the business or product KPI:
  https://www.evidentlyai.com/blog/ml-monitoring-metrics#4-business-metrics-and-kpi

      </section>



      <!-- <section data-markdown lang="de">
  ## Datenqualität
  
  * Felder
    * fehlen
    * ungültig
    * falsch / unplausibel / Wertebereich verlassen
  * Features 
    * konstante (die (meisten) Eingaben haben (fast) denselben Wert)
    * leere
    * fast leer
    * Korrelationen zwischen Features
  </section> -->

      <!-- <section data-markdown style="font-size: x-large;" lang="de" id="drift-interpretation">
	<textarea data-template>
## Drift erfordert Interpretation

Wenn die Welt sich ändert, ist Drift zu erwarten und damit ok

|   | Positive Interpretation, keine Maßnahme erforderlich  | Negative Interpretation, Maßnahme erforderlich  |
|---|---|---|
| *Data und Prediction Drift*  | wichtige Features haben sich geändert, Modell kommt klar und extrapoliert gut, z.B.: Höheres Alter, mehr Risiko  |  wichtige Features haben sich geändert, Modell extrapoliert nicht sinnvoll |
| *Data aber kein Prediction Drift*  | keine wichtigen Features geändert, das Modell ist robust genug für den Drift  | wichtige Features geändert, Modell extrapoliert nicht sinnvoll |
| *Prediction aber kein Data Drift*  | ???  | wahrscheinlich Concept Drift, neue Analyse der Situation notwendig |
|   |   |   |

</textarea>
</section> -->

      <section data-markdown style="font-size: x-large;" lang="en" id="drift-interpretation">
        <textarea data-template>
## Drift requires interpretation

When the world changes, drift is to be expected and therefore ok

|   | Positive interpretation, no action required  | Negative interpretation, action required  |
|---|---|---|
| *Data and Prediction Drift*  | important features have changed, model is fine and extrapolates well, e.g.: higher age, more risk  |  important features have changed, model does not extrapolate well |
| *Data but no Prediction Drift*  | no important features changed, model is robust enough for the drift  | important features have changed, model does not extrapolate well |
| *Prediction but no Data Drift*  | ???  | probably Concept Drift, new analysis of the situation necessary |
|   |   |   |

</textarea>
      </section>

      <!-- <section data-markdown lang="de" id="stats-test">
	<textarea data-template>
## Welcher Statistischer Test / welche Metrik?

es gibt leider nicht den einen passenden Test

* manche passen nur gut für kleine (< 1000) Datenmengen
  * unsere Datenmengen sind größer als 1000
* manche können nicht nur auf numerischen sondern kategorischen Daten arbeiten
  * wir brauchen beides
* manche sind zwischen 0 und 1 normiert
  * das ist uns eher egal
* unsere Metriken
  * Wasserstein Metrik für numerische Daten
  * Jensen-Shannon Distanz für kategorische Daten  

https://evidentlyai.com/blog/data-drift-detection-large-datasets
</textarea>
</section>
 -->
      <section data-markdown lang="en" id="stats-test">
        <textarea data-template>
## Which statistical test / which metric?

there is unfortunately not the one suitable test

* some only fit well for small (< 1000) data sets
  * our data sets are larger than 1000
* some can only work on numerical but not categorical data
  * we need both
* some are normalized between 0 and 1
  * we don't care about that
* our metrics
  * Wasserstein metric for numerical data
  * Jensen-Shannon distance for categorical data

* Drift algorithm: https://docs.evidentlyai.com/reference/data-drift-algorithm  
* When to use which metric: https://evidentlyai.com/blog/data-drift-detection-large-datasets
</textarea>
      </section>

      <!-- <section data-markdown lang="de" id="Wasserstein">
	<textarea data-template>
### Die Wasserstein-Metrik

_Wenn jede Verteilung als ein Haufen von „Erde“ angehäuft auf dem metrischen Raum betrachtet wird, dann beschreibt diese
Metrik die minimalen „Kosten“ der Umwandlung eines Haufens in den anderen._

* nicht zu sensitiv, zeigt nur größere Veränderungen an
* normiert in Veränderungen in Standardabweichungen
* kann (offensichtlich) über 1 gehen
* ab 0.1 gehen wir von einem Drift aus
* funktioniert nur für numerische Daten

https://en.wikipedia.org/wiki/Wasserstein_metric
</textarea>
</section>
 -->
      <section data-markdown lang="en" id="Wasserstein">
        <textarea data-template>
### Wasserstein Metric

_If each distribution is considered as a pile of "earth" piled up on the metric space, then this metric describes the
minimum "costs" of transforming one pile into the other._

* not too sensitive, only shows larger changes
* normalized in changes in standard deviations
* can (obviously) go over 1
* from 0.1 we assume a drift
* only works for numerical data

https://en.wikipedia.org/wiki/Wasserstein_metric
</textarea>
      </section>


      <!-- <section data-markdown lang="de" id="Jensen-Shannon">
	<textarea data-template>
### Jensen-Shannon Divergenz

* Jensen-Shannon Distanz ist Wurzel aus der Divergenz, das ist unsere Metrik
* zwischen 0 und 1
* ab 0.05 gehen wir von einem Drift aus
* funktioniert auch für kategorische Daten
* basiert auf Kullback–Leibler Divergenz, relative Entropie
* Histogramme werden verglichen, Größe des Samples daher egal
* Binning für kategorische Daten offensichtlich
* Intuition: wie viel Information/Entropie/Überraschung steckt im Unterschied der beiden Verteilungen?


https://en.wikipedia.org/wiki/Jensen%E2%80%93Shannon_divergence
https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence
</textarea>
</section>
 -->

      <section data-markdown lang="en" id="Jensen-Shannon">
        <textarea data-template>
### Jensen-Shannon Divergence

* Jensen-Shannon distance is square root of divergence, that is our metric
* between 0 and 1
* from 0.05 we assume a drift
* also works for categorical data
* based on Kullback–Leibler divergence, relative entropy
* histograms are compared, size of the sample therefore doesn't matter
* binning for categorical data obvious
* Intuition: how much information/entropy/surprise is in the difference of the two distributions?

https://en.wikipedia.org/wiki/Jensen%E2%80%93Shannon_divergence
https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence
</textarea>
      </section>

      <section data-markdown id="ml-system">
        <textarea data-template>
### A ML model does not go into production all by itself

<img src="img/ml-system-postits.jpg" style="height: 550px;">

</textarea>
      </section>


      <section data-markdown id="what-else">
        ### What else / more material
      </section>

      <!-- <section data-markdown class="fragments"  lang="de">
    <textarea data-template>
  ### Was kann man sonst noch machen
  
  * Outlier-Detection
    * Unser Modell wird nicht extrapolieren können
    * Werte außerhalb des Trainings-Bereichs werden wahrscheinlich unrealistisch sicher vorhergesagt
    * Ausreißer müssen ohne Ground Truth entdeckt werden 
  * Adversarial Detection
    * Bestimmte Eingaben können absichtlich eine grob falsche Vorhersage herbei führen 
    * Solche Eingaben können erkannt und korrigiert werden
    * Dazu kann z.B. ein Autoencoder benutzt werden, der die Eingabe korrigiert
  
  <small>https://docs.seldon.io/projects/alibi-detect/en/stable/od/methods.html
  <br>
  https://docs.seldon.io/projects/alibi-detect/en/stable/ad/methods.html
  </small>
  </textarea>
  </section> -->

      <section data-markdown class="fragments" lang="en">
        <textarea data-template>
  ### What else can be done

  * Outlier detection
    * Our model will not be able to extrapolate
    * Values outside the training range will often be predicted with an unrealistically high certainty
    * Outliers must be detected without ground truth
  * Adversarial Detection
    * Certain inputs can intentionally lead to a grossly wrong prediction
    * Such inputs can be detected and corrected
    * For this purpose, e.g. an autoencoder can be used, which corrects the input

  <small>https://docs.seldon.io/projects/alibi-detect/en/stable/od/methods.html
  <br>
  https://docs.seldon.io/projects/alibi-detect/en/stable/ad/methods.html
  </small>
  </textarea>
      </section>

      <!-- <section data-markdown class="fragments" lang="de">
    <textarea data-template>
  ### Drift Detection für Bilder
  
  _Bild auf typische aggregierte Eigenschaften reduzieren_  
  * Input Drift mit Histogrammen von Low-Level-Features (HSV): https://towardsdatascience.com/detecting-semantic-drift-within-image-data-6a59a0e768c6
  * Input Drift mit Dimensions-Reduktion: https://docs.seldon.io/projects/alibi-detect/en/stable/examples/cd_ks_cifar10.html 
  * Model Drift durch Vergleich mit destilliertem Modell: https://docs.seldon.io/projects/alibi-detect/en/stable/examples/cd_distillation_cifar10.html 
  * Ein komplettes Beispiel mit Alibi-Detect: https://docs.seldon.io/projects/alibi-detect/en/stable/examples/alibi_detect_deploy.html#4.-Drift-detection-with-Kolmogorov-Smirnov
  * Anomalien in Bildern: https://29a.ch/photo-forensics
  </textarea>
  </section> -->

      <section data-markdown class="fragments" lang="en">
        <textarea data-template>
### Drift Detection for Images

_Reduce image to typical aggregated properties_
* Input Drift with histograms of low-level features (HSV): https://towardsdatascience.com/detecting-semantic-drift-within-image-data-6a59a0e768c6
* Input Drift with dimension reduction: https://docs.seldon.io/projects/alibi-detect/en/stable/examples/cd_ks_cifar10.html
* Model Drift by comparing with distilled model: https://docs.seldon.io/projects/alibi-detect/en/stable/examples/cd_distillation_cifar10.html
* A complete example with Alibi-Detect: https://docs.seldon.io/projects/alibi-detect/en/stable/examples/alibi_detect_deploy.html#4.-Drift-detection-with-Kolmogorov-Smirnov
  </textarea>
      </section>


      <section data-markdown class="fragments">
        <textarea data-template>
### Drift Detection for Text

1. Text Descriptors Drift: compare the descriptive statistics of the text data, e.g. 
   1. length of text
   1. share of out-of-vocabulary words
   1. share of non-letter symbols
1. Domain Classifier / model-based drift detection 
   * If a model can reliably identify the reviews that belong to the current or reference dataset, the two datasets are probably sufficiently different.
   * Failing Loudly: An Empirical Study of Methods for Detecting Dataset Shift: https://arxiv.org/abs/1810.11953
   * can be applied to all kinds of data (including images)
1. Based on differences (eucledian, cosine, etc.) of averages of embeddings  

</textarea>
      </section>

      <section data-markdown>
        <textarea data-template>
### Drift Detection for Text - Links

* https://docs.seldon.io/projects/alibi-detect/en/stable/examples/cd_text_imdb.html
* https://www.evidentlyai.com/blog/unstructured-data-monitoring
* https://www.evidentlyai.com/blog/embedding-drift-detection
* https://www.evidentlyai.com/blog/how-deepl-monitors-ml-models
* https://www.evidentlyai.com/blog/tutorial-detecting-drift-in-text-data
  * https://archive.ics.uci.edu/dataset/462/drug+review+dataset+drugs+com
  * https://colab.research.google.com/drive/10RBYBM5phCckMNZ0QRnOOcx4YyAou9uP
* https://www.evidentlyai.com/blog/evidently-data-quality-monitoring-and-drift-detection-for-text-data
</textarea>
      </section>


      <!-- <section data-markdown class="fragments" lang="de">
    <textarea data-template>
  ### Wann liegt Ground Truth vor?
  
  *Menschliche Experten können die Ground Truth*
  * *bestimmen* 
    * sobald ein Mensch die Entscheidungen nachprüft / revidiert
    * bei einem Proposal-System kann das sehr schnell sein
    * bei Dunkelverarbeitung sollte dies in regelmäßigen Abständen passieren
  * *nicht bestimmen*
    * wir müssen Realitäten abwarten
    * bei Zeitreihen wird auf die nahe Zukunft vorhergesagt, sobald diese Eintritt kann überprüft werden
    * oft sind solche Realitäten erst nach einiger Zeit wahrnehmbar und unterliegen statistischen Schwankungen (wie bei uns)
  </textarea>
  </section> -->

      <section data-markdown class="fragments" lang="en">
        <textarea data-template>
### When do we have the Ground Truth?

*Human experts can*
* *determine ground truth*
  * as soon as a human checks/revises the decisions
  * for a proposal system this can be very fast
  * for dark processing this should happen at regular intervals
* *not determine ground truth*
  * we have to wait for realities
  * in time series, predictions are made for the near future, as soon as this occurs it can be checked
  * often such realities are only perceptible after some time and are subject to statistical fluctuations (as in this example)
  </textarea>
      </section>



      <!-- <section data-markdown class="fragments" lang="de">
    <textarea data-template>
  ### Unsere Vorhersage selbst erzeugt Drift
  
  * Ein Deployment ändert das unsere Rolle von Beobachter zu Akteur
  * Wir versichern nur Leute mit einer guten Risiko Prognose
    * Wenn nicht, warum sollten wir dann eine überhaupt eine Prognose machen?
  * Unsere GT wird mehr und mehr gute Fahrer haben
    * Zumindest ist das unsere Hoffnung (sonst hätte die Prognose nicht geklappt)
  * Falls nicht (False Negative, Type II Fehler)
    * haben Menschen gelernt, unser System auszutricksen?
    * "Dann versichert eben meine Tochter den Wagen"
  * Haben wir gute Fahrer aus Versehen nicht versichert (False Positive, Type I Fehler)
    * Möglichkeit: *epsilon-greedy* meistens der Vorhersage glauben, aber manchmal (epsilon) auch einen Fahrer mit schlechter Prognose versichern 
    * Vorhersage mit allen Wahrscheinlichkeiten geht in unsere Datenbank ein
  
  https://twitter.com/ChristophMolnar/status/1569644089724764160
  </textarea>
  </section> -->

      <section data-markdown class="fragments" lang="en">
        <textarea data-template>
### Our prediction itself creates drift

* A deployment changes our role from observer to actor
* We only insure people with a good risk forecast
  * If not, why should we make a forecast at all?
* Our GT will have more and more good drivers
  * At least that is our hope (otherwise the forecast would not have worked)
* If not (False Negative, Type II Error)
  * have people learned to trick our system?
  * "Then my daughter will insure the car"
* Have we accidentally not insured good drivers (False Positive, Type I Error)
  * Possibility: *epsilon-greedy* mostly believe the prediction, but sometimes (epsilon) also insure a driver with a bad forecast
  * Prediction with all probabilities goes into our database

  https://twitter.com/ChristophMolnar/status/1569644089724764160
  </textarea>
      </section>


      <section data-markdown>
        <textarea data-template>
### Google Rubric Score
* https://developers.google.com/machine-learning/guides/rules-of-ml
* https://research.google/pubs/pub46555/
* https://research.google/pubs/pub45742/
* https://laszlo.substack.com/p/article-review-the-ml-test-score
    </textarea>
      </section>

      <section data-markdown>
        <textarea data-template>
### Challenges in Machine Learning Projects

<img src="img/biggest_challenges_ML_MLCon_2023.jpg" style="height: 530px;" class="fragment">

<small>Survey MLConf Berlin 2023</small>
	</textarea>
      </section>


      <section data-markdown>
        <textarea data-template>
  ### Machine Learning Projecs can be thought as running in phases
  
  <img src='img/ml-phases-small-en.jpg' style="height: 100%;">
  
  </textarea>
      </section>

      <!--

<section data-markdown class="preparation">
	<textarea data-template>
1. 30 Zines vorbereiten und mitbrigen
1. Gitpod starten
   1. im Workspace auch die lokale installation machen
1. Lokale installation starten
   * ich hab eine lokale Installation auf meinem Rechner, falls irgendwas nicht geht
	</textarea>
</section>

<section data-markdown>
	<textarea data-template>
## Why this workshop?    

_I have rarely been this excited about a workshop like this one_
We have all skills coming together for this kind of work:
1. DS, mostly second part
1. Dev
1. Ops    
	</textarea>
</section>



<section data-markdown class="fragments">
  ### MLOps
  
  * MLOps is derived from DevOps
  * MLOps brings ML into production and keeps it in operation
  * A number of tools and practices are used for this
  * Overlap from
    * Software development
    * Operations
    * Data Science
  </section>
  
  
<section data-markdown>
### MLOps 1.0 vs MLOps 2.0

- MLOps 1.0 - research / experiment centric
- MLOps 2.0 - production first
</section>

<section data-markdown>
### MLOps 1.0 - research / experiment centric

  - Managing experiments  and Version control
    - Model Architecture
    - Training Code
    - Data
    - Artefacts
      - Trained Model 
      - Plots (learning curve, confusion matrix)
  - Tools
    - Mlflow
    - Speadsheets
    - Weights & Biases
    - Comet
</section>

<section data-markdown>
### MLOps 2.0 - production first

  - productionize, deploy, maintain
  - Deployment Pipeline
     - Model Repo
       - Rather Image, as Model does not stand for itself most of the time, rather is a system
       - Data Source and Preproc same code dev and prod (if possible)
  - Real world environment
  - Monitoring
    - Gap between training and prod data?
</section>

<section data-markdown>
	<textarea data-template>
### Fun for the first five minutes
## Create your own MLOps Zine

<div class="container">
  <div class="col">
  <img src="img/zine/teaser.jpg" style="height: 100%;">
  <em>Fold</em>
  </div>
  <div class="col">
  <img src="img/zine/fold.jpg" style="height: 100%;">
  <em>Topology change</em>
  
  </div>
</div>
<br>  
<br>  

<small>We are not aiming for highest production quality, but make something physical that you can take home</small>
</textarea>
</section> -->

      <!-- <section data-markdown>
	<textarea data-template>
### MLOps - komplettes Zine

<img src="img/zine/mlops.png" style="height: 530px;" class="fragment">

<small>Bildunterschrit</small>
	</textarea>
</section>
 -->

      <!-- 

  <section data-markdown>
    <textarea data-template>
    ### Machine Learning Projecs can be thought as running in phases
    
    <img src='img/ml-phases-en.jpg' style="height: 100%;">
    
    </textarea>
  </section>
  
  
  <section data-markdown>
  ### Phase 0: Enable Organization
  
  _Make sure people on all levels and all roles understand the specific needs and specialties of a machine learning project_
  
  * prepare for 80% garbage factor
  * clash of roles
  * largest part of job begins *after* production
  * this might be the hardest and least part of the overall job
  
  Links
  * https://fearlesschangepatterns.com/
  * https://www.rejectiontherapy.com/
  </section>
  
  <section data-markdown>
    <textarea data-template>
  ### Phase 1: Data Engineering
    
    _Make sure you have a reliable, reproducible and scalable data pipeline_
    
    * data versioning
    * data validation
    * data reproducibility
    * data scalability
    
    Links
    * https://www.kdnuggets.com/2021/03/data-version-control-what-why-how.html
    *
  </textarea>
  </section>
  
     -->

    </div>
  </div>
  <script src="revealjs/reveal.js/dist/reveal.js"></script>
  <script src="revealjs/reveal.js/plugin/notes/notes.js"></script>
  <script src="revealjs/reveal.js/plugin/markdown/markdown.js"></script>
  <script src="revealjs/reveal.js/plugin/highlight/highlight.js"></script>
  <script src="revealjs/config.js"></script>

</body>

</html>